#### Numpy

***1.numpy.tile(A, reps)***

```python
（1） 通过重复reps次A来构造出一个新数组
>>> import numpy as np
>>> a = np.array([0, 1, 2])
>>> np.tile(a, 2)
array([0, 1, 2, 0, 1, 2])
```

```python
(2)如果参数reps存在长度 d = len(reps) 的话，那么函数返回的新数组的维数就是 max(d, A.ndim)
'''
如果 A.ndim < d 的话，A就会通过加上新的轴来提升到d维，因此，一个shape 为(3,) 的数组就会被提升到(1, 3) 成为2维复制品，或者被提升到(1, 1, 3) 成为3维复制品。如果这不是期望的行为，那就在调用这个函数之前手动把A提升到d维。
如果 A.ndim > d 的话，reps就会通过在最前面加多个1来提升到A.ndim 维。因此，当A的shape 为(2, 3, 4, 5) 时，为(2, 2) 的reps就会被处理成(1, 1, 2, 2) 然后再参与函数计算，返回的新数组的shape应该是(2, 3, 8, 10)。
'''
>>> np.tile(a, (2, 2))
array([[0, 1, 2, 0, 1, 2],
       [0, 1, 2, 0, 1, 2]])
>>> np.tile(a, (2, 1, 2))
array([[[0, 1, 2, 0, 1, 2]],
       [[0, 1, 2, 0, 1, 2]]])
>>> np.tile(a, (2,3,4))
array([[[0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],
        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],
        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]],

       [[0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],
        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2],
        [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]]])
>>> y.shape
(2, 3, 4, 5)

#y.ndim > d，y的维度小于reps的长度，所以z应该是一个4维的数组
>>> z = tile(y, (2,2))  
>>>z.shape
(2, 3, 8, 10)
```

***2.numpy.transpose() 从元素转置的角度理解***

***3.numpy.clip(a, a_min, a_max, out=None)[source]***

```python
clip这个函数将将数组中的元素限制在a_min, a_max之间，大于a_max的就使得它等于 a_max，小于a_min,的就使得它等于a_min。
```

#### Python

```python
1.# x1, y1 = not_repeat_points[i][0], not_repeat_points[i][1]
(x1, y1) = not_repeat_points[i]

2.slope["{}/{}".format(dy, dx)] += oints_dict[not_repeat_points[j]]

3.points_dict = Counter(tuple(point) for point in points)
```

###### **2.collections.defaultdict用法（记住三种用法）**

```
用例1>>> s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]
>>> d = defaultdict(list)
>>> for k, v in s:
...     d[k].append(v)
...
>>> d.items()
[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]
用例2>>> s = 'mississippi'
>>> d = defaultdict(int)
>>> for k in s:
...     d[k] += 1
...
>>> d.items()
[('i', 4), ('p', 2), ('s', 4), ('m', 1)]
用例3>>> s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)]
>>> d = defaultdict(set)
>>> for k, v in s:
...     d[k].add(v)
...
>>> d.items()
[('blue', set([2, 4])), ('red', set([1, 3]))]
```

###### **3.math.floor(), math.ceil()计算上下界**

###### **4.list的深层拷贝和浅层拷贝**

首先，我们看下面一段代码：

```python
f = [1, 2, 3, 4, 5]
res = []
res.append(f)
for i in range(5):
    for j in range(len(f)):
        f[j] += 1
    res.append(f)
print(res)
```

输出结果为：

```python
[[6, 7, 8, 9, 10], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10]]
```

**what？？**

其实这是python中的一个陷阱，list内部存储的list其实是内部list的引用。

list(**list**)内部的list存储的是引用

再来重温一下python中深拷贝和浅拷贝的问题

```python
案例一 浅层拷贝  
>>>a = {1: [1,2,3]}
>>> b = a.copy()
>>> a, b
({1: [1, 2, 3]}, {1: [1, 2, 3]})
>>> a[1].append(4)
>>> a, b
({1: [1, 2, 3, 4]}, {1: [1, 2, 3, 4]})
```

<img src="C:\Users\Ji Haobo\AppData\Roaming\Typora\typora-user-images\image-20201031140048227.png" alt="image-20201031140048227"  />

------

直接赋值

![image-20201031140236427](C:\Users\Ji Haobo\AppData\Roaming\Typora\typora-user-images\image-20201031140236427.png)

------

```python
案例2 深层拷贝
>>>import copy
>>> c = copy.deepcopy(a)
>>> a, c
({1: [1, 2, 3, 4]}, {1: [1, 2, 3, 4]})
>>> a[1].append(5)
>>> a, c
({1: [1, 2, 3, 4, 5]}, {1: [1, 2, 3, 4]})
```

![image-20201031140350075](C:\Users\Ji Haobo\AppData\Roaming\Typora\typora-user-images\image-20201031140350075.png)

###### 5.整数的最大值和最小值

```
import sys
sys.maxsize 再大就变成long型
-sys.maxsize-1

float('inf')
float('-inf')
```

#### Pytorch

###### 1.PyTorch几种情况下的参数数量统计

```python
(1)没有共享参数，使用torchsummary计算
(2)使用共享参数，自己定义计算
# -*- coding: utf-8 -*-
import torch
import torch.nn as nn
import torchsummary
from torch.nn import init
class BaseNet(nn.Module):
    def __init__(self):
        super(BaseNet,self).__init__()
        self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False)
        self.conv2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight.data)
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                init.normal_(m.weight.data, 1.0, 0.02)
                init.constant_(m.bias.data, 0.0)
    def forward(self,x):
        x=self.conv1(x)
        out_map=self.conv2(x)
        return out_map
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)
# model.parameters()是取得模型的参数，if p.requires_grad 是可求导参数的情况下。其实在定义网络的时候基本上都是可求导参数，包括卷积层参数，BN层参数，所以我们统计可求导参数。然后numel()是统计numpy数组里面的元素的个数。这样一来就很明显了，我们定义了两个3x3卷积层，而且没有bias，所以参数个数是3x3x2=18个，网络结构是两层.

model = BaseNet()
torchsummary.summary(model, (1, 512, 512))
print('parameters_count:',count_parameters(model))

model = BaseNet()
torchsummary.summary(model, (1, 512, 512))
print('parameters_count:',count_parameters(model))
```

**Note**:使用count_parameters()时，也要将foward中未使用，但init时初始化的层注释掉，否则这种方法也会出现error.

###### 2.pytorch计算FLOPs(模型的计算量)

```
PyTorch-OpCounter 的安装和使用都非常简单，并且还能定制化统计规则，因此那些特殊的运算也能自定义地统计进去
我们可以使用 pip 简单地完成安装：pip install thop。不过 GitHub 上的代码总是最新的，因此也可以从 GitHub 上的脚本安装。
```

```python
#Define the rule for 3rd party module.
class YourModule(nn.Module):
    # your definition
def count_your_model(model, x, y):
    # your rule here

input = torch.randn(1, 3, 224, 224)
macs, params = profile(model, inputs=(input, ), 
                        custom_ops={YourModule: count_your_model})
```

```python
#Improve the output readability
#Call thop.clever_format to give a better format of the output.
from thop import clever_format
macs, params = clever_format([macs, params], "%.3f")
```

https://github.com/Lyken17/pytorch-OpCounter